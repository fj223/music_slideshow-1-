import os
import sys
import argparse
import time
from datetime import datetime
import logging

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# ç¡®ä¿logsç›®å½•å­˜åœ¨
LOGS_DIR = os.path.join(PROJECT_ROOT, 'logs')
os.makedirs(LOGS_DIR, exist_ok=True)

# è®¾ç½®æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOGS_DIR, 'pipeline.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# æ¨¡å—å¯¼å…¥å¤„ç†
class DummyTextProcessor:
    """æ–‡æœ¬å¤„ç†å™¨çš„å¤‡ç”¨å®ç°"""
    def split_sentences(self, text):
        # ç®€å•çš„å¥å­åˆ†å‰²å®ç°
        import re
        # åŸºæœ¬çš„å¥å­åˆ†å‰²ï¼Œæ”¯æŒä¸­è‹±æ–‡æ ‡ç‚¹
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\s*', text)
        return [s.strip() for s in sentences if s.strip()]

class DummyImageManager:
    """å›¾åƒç®¡ç†å™¨çš„å¤‡ç”¨å®ç°"""
    def generate_images_from_sentences(self, sentences):
        # è¿”å›æµ‹è¯•å›¾åƒè·¯å¾„
        test_images_dir = os.path.join(OUTPUT_DIR, 'videos', 'test_images')
        if os.path.exists(test_images_dir):
            # ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•å›¾åƒ
            image_paths = []
            for i in range(min(len(sentences), 10)):  # æœ€å¤šä½¿ç”¨10å¼ å›¾åƒ
                img_path = os.path.join(test_images_dir, f'test_image_{i+1}.png')
                if os.path.exists(img_path):
                    image_paths.append(img_path)
            return image_paths
        return []

# å°è¯•å¯¼å…¥æ¨¡å—
try:
    from utils.audio_processor import AudioProcessor
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥AudioProcessorï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    class AudioProcessor:
        def __init__(self, model_size):
            self.model_size = model_size
        def transcribe_audio(self, audio_path):
            return "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è½¬å½•æ–‡æœ¬ã€‚ç”¨äºæ¼”ç¤ºéŸ³ä¹å¹»ç¯ç‰‡åŠŸèƒ½ã€‚"
        def split_into_sentences(self, text, language):
            import re
            return re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\s*', text)

try:
    from utils.text_processor import TextProcessor
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥TextProcessorï¼Œä½¿ç”¨å¤‡ç”¨å®ç°")
    TextProcessor = DummyTextProcessor

try:
    from utils.image_manager import ImageManager
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥ImageManagerï¼Œä½¿ç”¨å¤‡ç”¨å®ç°")
    ImageManager = DummyImageManager

try:
    from utils.video_creator import VideoCreator
except ImportError:
    logger.error("æ— æ³•å¯¼å…¥VideoCreatoræ¨¡å—")
    print("é”™è¯¯: æ— æ³•å¯¼å…¥VideoCreatoræ¨¡å—ï¼Œè¿™æ˜¯å¿…è¦çš„")
    sys.exit(1)

try:
    from config import INPUT_DIR, OUTPUT_DIR, WHISPER_CONFIG, IMAGE_CONFIG
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥configï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    # é»˜è®¤é…ç½®
    INPUT_DIR = os.path.join(PROJECT_ROOT, 'input')
    OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'output')
    WHISPER_CONFIG = {"model_size": "small", "language": "zh"}
    IMAGE_CONFIG = {"max_images": 10}
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(INPUT_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)


class MusicSlideshowPipeline:
    def __init__(self):
        """åˆå§‹åŒ–éŸ³ä¹å¹»ç¯ç‰‡ç”Ÿæˆç®¡é“"""
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–éŸ³ä¹å¹»ç¯ç‰‡ç®¡é“")
            # æ·»åŠ å¼‚å¸¸å¤„ç†å’Œå‚æ•°éªŒè¯
            if "model_size" not in WHISPER_CONFIG:
                raise ValueError("WHISPER_CONFIGä¸­ç¼ºå°‘å¿…è¦çš„'model_size'é…ç½®")
                
            self.audio_processor = AudioProcessor(model_size=WHISPER_CONFIG["model_size"])
            self.text_processor = TextProcessor()
            self.image_manager = ImageManager()
            self.video_creator = VideoCreator()
            
            logger.info("éŸ³ä¹å¹»ç¯ç‰‡ç®¡é“åˆå§‹åŒ–å®Œæˆ")
            print("ğŸµ éŸ³ä¹å¹»ç¯ç‰‡ç®¡é“åˆå§‹åŒ–å®Œæˆ!")
            
        except Exception as e:
            logger.error(f"ç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise RuntimeError(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def process_audio_to_video(self, audio_path, output_name=None, max_images=None, 
                              transition_type='fade', video_resolution=None):
        """
        å®Œæ•´çš„éŸ³é¢‘åˆ°è§†é¢‘å¤„ç†æµç¨‹
        
        Args:
            audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_name (str, optional): è¾“å‡ºè§†é¢‘æ–‡ä»¶å
            max_images (int, optional): æœ€å¤§å›¾åƒç”Ÿæˆæ•°é‡
            transition_type (str, optional): è½¬åœºæ•ˆæœç±»å‹
            video_resolution (tuple, optional): è§†é¢‘åˆ†è¾¨ç‡ (width, height)
            
        Returns:
            str or None: æˆåŠŸæ—¶è¿”å›è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        start_time = datetime.now()
        step_results = {
            "transcription": None,
            "sentences": [],
            "image_paths": [],
            "video_path": None
        }
        
        try:
            # éªŒè¯è¾“å…¥éŸ³é¢‘æ–‡ä»¶
            if not os.path.exists(audio_path):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            
            # éªŒè¯éŸ³é¢‘æ–‡ä»¶æ ¼å¼
            if not any(audio_path.lower().endswith(ext) for ext in ['.mp3', '.wav', '.m4a', '.flac', '.ogg']):
                logger.warning(f"éæ ‡å‡†éŸ³é¢‘æ ¼å¼: {audio_path}")
                print(f"âš ï¸  è­¦å‘Š: éæ ‡å‡†éŸ³é¢‘æ ¼å¼ï¼Œå¯èƒ½ä¸è¢«æ”¯æŒ: {audio_path}")
            
            print("=" * 60)
            print("ğŸš€ å¼€å§‹éŸ³ä¹å¹»ç¯ç‰‡ç”Ÿæˆæµç¨‹")
            print(f"ğŸ“ è¾“å…¥éŸ³é¢‘: {audio_path}")
            print(f"â±ï¸  å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 60)
            
            # æ­¥éª¤1: è¯­éŸ³è¯†åˆ«
            print("\nğŸ“ æ­¥éª¤ 1/4: è¯­éŸ³è¯†åˆ«")
            step_start = time.time()
            text = self._run_transcription(audio_path, step_results)
            self._log_step_time("è¯­éŸ³è¯†åˆ«", time.time() - step_start)
            
            if not text or len(text.strip()) < 5:
                print("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥æˆ–æ–‡æœ¬å¤ªçŸ­")
                return None
            
            # æ­¥éª¤2: æ–‡æœ¬å¤„ç†
            print("\nğŸ”¤ æ­¥éª¤ 2/4: æ–‡æœ¬å¤„ç†")
            step_start = time.time()
            sentences = self._process_text(text, step_results)
            self._log_step_time("æ–‡æœ¬å¤„ç†", time.time() - step_start)
            
            if not sentences:
                print("âŒ æ— æ³•ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆå¥å­")
                return None
            
            # æ­¥éª¤3: å›¾åƒç”Ÿæˆ
            print("\nğŸ¨ æ­¥éª¤ 3/4: å›¾åƒç”Ÿæˆ")
            step_start = time.time()
            image_paths = self._generate_images(sentences, max_images, step_results)
            self._log_step_time("å›¾åƒç”Ÿæˆ", time.time() - step_start)
            
            if not image_paths:
                print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å›¾åƒ")
                return None
            
            # æ­¥éª¤4: è§†é¢‘åˆæˆ
            print("\nğŸ¬ æ­¥éª¤ 4/4: è§†é¢‘åˆæˆ")
            step_start = time.time()
            video_path = self._create_video(image_paths, audio_path, output_name, 
                                          transition_type, video_resolution, step_results)
            self._log_step_time("è§†é¢‘åˆæˆ", time.time() - step_start)
            
            if video_path:
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                print("=" * 60)
                print("ğŸ‰ éŸ³ä¹å¹»ç¯ç‰‡ç”Ÿæˆå®Œæˆ!")
                print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                print(f"   æ€»è€—æ—¶: {duration:.2f} ç§’")
                print(f"   å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"   ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"   å¤„ç†éŸ³é¢‘: {os.path.basename(audio_path)}")
                print(f"   ç”Ÿæˆå›¾åƒ: {len(image_paths)} å¼ ")
                print(f"   è¾“å‡ºè§†é¢‘: {video_path}")
                print(f"   è½¬åœºæ•ˆæœ: {transition_type}")
                if video_resolution:
                    print(f"   è§†é¢‘åˆ†è¾¨ç‡: {video_resolution[0]}x{video_resolution[1]}")
                print("=" * 60)
                
                logger.info(f"éŸ³ä¹å¹»ç¯ç‰‡ç”ŸæˆæˆåŠŸï¼Œè¾“å‡º: {video_path}")
                return video_path
            else:
                print("âŒ è§†é¢‘åˆæˆå¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)
            print(f"âŒ å¤„ç†å‡ºé”™: {str(e)}")
            print("\nğŸ” é”™è¯¯è¯¦æƒ…:")
            print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            
            # å°è¯•æ¸…ç†éƒ¨åˆ†ç”Ÿæˆçš„èµ„æº
            self._cleanup_resources(step_results)
            return None
    
    def _run_transcription(self, audio_path, step_results):
        """æ‰§è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            text = self.audio_processor.transcribe_audio(audio_path)
            
            # ä¿å­˜è½¬å½•æ–‡æœ¬
            transcript_dir = os.path.join(OUTPUT_DIR, "transcribed")
            os.makedirs(transcript_dir, exist_ok=True)
            
            base_name = os.path.splitext(os.path.basename(audio_path))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            transcript_file = os.path.join(transcript_dir, f"{base_name}_{timestamp}_transcript.txt")
            
            with open(transcript_file, 'w', encoding='utf-8') as f:
                f.write(text)
            
            print(f"âœ… è½¬å½•æ–‡æœ¬å·²ä¿å­˜: {transcript_file}")
            print(f"ğŸ“ è¯†åˆ«åˆ°æ–‡æœ¬ ({len(text)} å­—ç¬¦)")
            
            # æ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
            if len(text) > 100:
                print(f"   æ–‡æœ¬é¢„è§ˆ: {text[:100]}...")
            else:
                print(f"   æ–‡æœ¬å†…å®¹: {text}")
                
            step_results["transcription"] = text
            return text
            
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            raise RuntimeError(f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {str(e)}")
    
    def _process_text(self, text, step_results):
        """å¤„ç†è¯†åˆ«åˆ°çš„æ–‡æœ¬"""
        try:
            # è·å–è¯­è¨€é…ç½®
            language = WHISPER_CONFIG.get("language", "zh")
            print(f"ğŸŒ æ£€æµ‹è¯­è¨€: {language}")
            
            sentences = self.audio_processor.split_into_sentences(text, language)
            
            if not sentences:
                # å°è¯•ä½¿ç”¨æ–‡æœ¬å¤„ç†å™¨çš„å¤‡ç”¨åˆ†å‰²æ–¹æ³•
                sentences = self.text_processor.split_sentences(text)
            
            # ä¿å­˜å¥å­åˆ°æ–‡ä»¶
            if sentences:
                sentences_dir = os.path.join(OUTPUT_DIR, "sentences")
                os.makedirs(sentences_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                sentences_file = os.path.join(sentences_dir, f"sentences_{timestamp}.txt")
                
                with open(sentences_file, 'w', encoding='utf-8') as f:
                    for i, sentence in enumerate(sentences, 1):
                        f.write(f"{i}. {sentence}\n")
                
                print(f"âœ… å¥å­æ–‡ä»¶å·²ä¿å­˜: {sentences_file}")
                print(f"ğŸ“„ è¯†åˆ«åˆ° {len(sentences)} ä¸ªå¥å­")
                
                # æ˜¾ç¤ºå‰3ä¸ªå¥å­
                for i, sentence in enumerate(sentences[:3], 1):
                    print(f"   {i}. {sentence}")
                if len(sentences) > 3:
                    print(f"   ... ç­‰ {len(sentences) - 3} ä¸ªå¥å­")
                    
            step_results["sentences"] = sentences
            return sentences
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
            raise RuntimeError(f"æ–‡æœ¬å¤„ç†å‡ºé”™: {str(e)}")
    
    def _generate_images(self, sentences, max_images, step_results):
        """ç”Ÿæˆå›¾åƒ"""
        try:
            # å¦‚æœæœ‰è‡ªå®šä¹‰çš„æœ€å¤§å›¾åƒæ•°é‡ï¼Œæ›´æ–°é…ç½®
            original_max = None
            if max_images is not None:
                original_max = IMAGE_CONFIG.get("max_images")
                IMAGE_CONFIG["max_images"] = max_images
                print(f"ğŸ“Š ä½¿ç”¨è‡ªå®šä¹‰æœ€å¤§å›¾åƒæ•°é‡: {max_images} (åŸé…ç½®: {original_max})")
            
            # é™åˆ¶å¥å­æ•°é‡
            if sentences and max_images and len(sentences) > max_images:
                print(f"âœ‚ï¸  å¥å­æ•°é‡è¿‡å¤šï¼Œå°†å‰ {max_images} ä¸ªå¥å­ç”¨äºå›¾åƒç”Ÿæˆ")
                sentences = sentences[:max_images]
            
            # ç”Ÿæˆå›¾åƒ
            image_paths = self.image_manager.generate_images_from_sentences(sentences)
            
            # æ¢å¤åŸå§‹é…ç½®
            if original_max is not None:
                IMAGE_CONFIG["max_images"] = original_max
            
            # éªŒè¯å›¾åƒç”Ÿæˆ
            if image_paths:
                print(f"âœ… æˆåŠŸç”Ÿæˆ {len(image_paths)} å¼ å›¾åƒ")
                # æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒè·¯å¾„
                for i, img_path in enumerate(image_paths[:5], 1):
                    print(f"   {i}. {os.path.basename(img_path)}")
                if len(image_paths) > 5:
                    print(f"   ... ç­‰ {len(image_paths) - 5} å¼ å›¾åƒ")
            else:
                print("âŒ å›¾åƒç”Ÿæˆå¤±è´¥æˆ–æ²¡æœ‰è¿”å›æœ‰æ•ˆå›¾åƒè·¯å¾„")
                
            step_results["image_paths"] = image_paths
            return image_paths
            
        except Exception as e:
            logger.error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            raise RuntimeError(f"å›¾åƒç”Ÿæˆå‡ºé”™: {str(e)}")
    
    def _create_video(self, image_paths, audio_path, output_name, 
                     transition_type, video_resolution, step_results):
        """åˆ›å»ºè§†é¢‘"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if output_name is None:
                base_name = os.path.splitext(os.path.basename(audio_path))[0]
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_name = f"{base_name}_slideshow_{timestamp}.mp4"
            
            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæ ¼å¼æ­£ç¡®
            if not output_name.endswith('.mp4'):
                output_name += '.mp4'
            
            # è°ƒç”¨è§†é¢‘åˆ›å»ºå™¨
            print(f"ğŸ”„ æ­£åœ¨åˆæˆè§†é¢‘... (è½¬åœº: {transition_type})")
            if video_resolution:
                print(f"ğŸ“ ä½¿ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡: {video_resolution[0]}x{video_resolution[1]}")
            
            # å°†å‚æ•°ä¼ é€’ç»™è§†é¢‘åˆ›å»ºå™¨
            video_path = self.video_creator.create_slideshow(
                image_paths, 
                audio_path, 
                output_name,
                transition_type=transition_type,
                resolution=video_resolution
            )
            
            if video_path and os.path.exists(video_path):
                file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
                print(f"âœ… è§†é¢‘åˆæˆæˆåŠŸ: {video_path}")
                print(f"ğŸ“Š è§†é¢‘æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
            else:
                print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                video_path = None
                
            step_results["video_path"] = video_path
            return video_path
            
        except Exception as e:
            logger.error(f"è§†é¢‘åˆæˆå¤±è´¥: {e}")
            raise RuntimeError(f"è§†é¢‘åˆæˆå‡ºé”™: {str(e)}")
    
    def _log_step_time(self, step_name, seconds):
        """è®°å½•æ­¥éª¤æ‰§è¡Œæ—¶é—´"""
        print(f"âœ… {step_name}å®Œæˆ! è€—æ—¶: {seconds:.2f} ç§’")
    
    def _cleanup_resources(self, step_results):
        """æ¸…ç†éƒ¨åˆ†ç”Ÿæˆçš„èµ„æºï¼ˆå¯é€‰ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ èµ„æºæ¸…ç†é€»è¾‘ï¼Œå¦‚ä¸´æ—¶æ–‡ä»¶ç­‰
            pass
        except:
            pass


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="éŸ³ä¹å¹»ç¯ç‰‡è§†é¢‘ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ç¤ºä¾‹:
  python main.py input/song.mp3
  python main.py input/song.mp3 -o my_video.mp4 -m 10
  python main.py input/song.mp3 -t zoom -r 1920 1080""")
    
    parser.add_argument("audio_file", nargs='?', help="è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (MP3, WAVç­‰)")
    parser.add_argument("-o", "--output", help="è¾“å‡ºè§†é¢‘æ–‡ä»¶å")
    parser.add_argument("-m", "--max-images", type=int, help="æœ€å¤§å›¾åƒç”Ÿæˆæ•°é‡")
    parser.add_argument("-t", "--transition", default="fade", 
                      choices=["fade", "slide", "zoom", "crossfade"],
                      help="è½¬åœºæ•ˆæœç±»å‹ (é»˜è®¤: fade)")
    parser.add_argument("-r", "--resolution", nargs=2, type=int, metavar=('WIDTH', 'HEIGHT'),
                      help="è§†é¢‘åˆ†è¾¨ç‡ï¼Œå¦‚ 1920 1080")
    parser.add_argument("--test", action="store_true", help="è¿è¡Œæµ‹è¯•æ¨¡å¼")
    
    return parser.parse_args()


def show_welcome_message():
    """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
    welcome = """
    ğŸµ éŸ³ä¹å¹»ç¯ç‰‡è§†é¢‘ç”Ÿæˆå™¨ ğŸµ
    ====================================================
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºå¸¦å›¾åƒçš„å¹»ç¯ç‰‡è§†é¢‘
    æ”¯æŒè¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬å¤„ç†ã€å›¾åƒç”Ÿæˆå’Œè§†é¢‘åˆæˆ
    ====================================================
    """
    print(welcome)


def main():
    """ä¸»å‡½æ•°"""
    show_welcome_message()
    args = parse_arguments()
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•æ¨¡å¼
    if args.test:
        print("ğŸ” è¿è¡Œæµ‹è¯•æ¨¡å¼...")
        try:
            from utils.video_creator import test_video_creation
            test_video_creation()
            return
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ¨¡å¼è¿è¡Œå¤±è´¥: {e}")
            return
    
    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å‚æ•°
    if not args.audio_file:
        print("âŒ é”™è¯¯: ç¼ºå°‘éŸ³é¢‘æ–‡ä»¶å‚æ•°")
        print("\nç”¨æ³•:")
        print("  python main.py <éŸ³é¢‘æ–‡ä»¶> [-o è¾“å‡ºæ–‡ä»¶å] [-m æœ€å¤§å›¾åƒæ•°é‡] [-t è½¬åœºæ•ˆæœ] [-r åˆ†è¾¨ç‡]")
        print("  python main.py --test  # è¿è¡Œæµ‹è¯•æ¨¡å¼")
        
        # æä¾›äº¤äº’å¼è¾“å…¥
        print("\nğŸ’¬ äº¤äº’å¼è¾“å…¥:")
        audio_file = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æˆ–è¾“å…¥'test'è¿è¡Œæµ‹è¯•): ").strip()
        
        if not audio_file:
            print("âŒ æ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
            return
        
        if audio_file.lower() == 'test':
            print("ğŸ” è¿è¡Œæµ‹è¯•æ¨¡å¼...")
            try:
                from utils.video_creator import test_video_creation
                test_video_creation()
                return
            except Exception as e:
                print(f"âŒ æµ‹è¯•æ¨¡å¼è¿è¡Œå¤±è´¥: {e}")
                return
        
        args.audio_file = audio_file
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.audio_file):
        print(f"âŒ é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {args.audio_file}")
        return
    
    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {args.audio_file}")
    if args.output:
        print(f"ğŸ¬ è¾“å‡ºæ–‡ä»¶: {args.output}")
    if args.max_images:
        print(f"ğŸ“Š æœ€å¤§å›¾åƒ: {args.max_images}")
    print(f"ğŸï¸  è½¬åœºæ•ˆæœ: {args.transition}")
    if args.resolution:
        print(f"ğŸ“ è§†é¢‘åˆ†è¾¨ç‡: {args.resolution[0]}x{args.resolution[1]}")
    print()
    
    # è¿è¡Œç®¡é“
    try:
        pipeline = MusicSlideshowPipeline()
        result = pipeline.process_audio_to_video(
            args.audio_file,
            args.output,
            args.max_images,
            args.transition,
            args.resolution
        )
        
        if result:
            print(f"\nâœ… å¤„ç†å®Œæˆ! è§†é¢‘æ–‡ä»¶: {result}")
            print(f"\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•è§†é¢‘æ’­æ”¾å™¨æŸ¥çœ‹ç”Ÿæˆçš„å¹»ç¯ç‰‡è§†é¢‘ã€‚")
        else:
            print("\nâŒ å¤„ç†å¤±è´¥!")
            print("\nğŸ’¡ å»ºè®®: è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        logger.error(f"ä¸»ç¨‹åºè¿è¡Œå¤±è´¥: {e}", exc_info=True)


if __name__ == "__main__":
    main()