#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘åˆ°è§†é¢‘çš„å®Œæ•´å¤„ç†æµç¨‹

æ­¤è„šæœ¬å°†ï¼š
1. ä½¿ç”¨ audio_to_images.py å°†éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬å¹¶ç”Ÿæˆå¯¹åº”å›¾ç‰‡
2. ä½¿ç”¨ video_creator.py å°†ç”Ÿæˆçš„å›¾ç‰‡è½¬æ¢ä¸ºè§†é¢‘
3. å¯é€‰ï¼šæ·»åŠ æ–‡å­—å åŠ åˆ°è§†é¢‘
"""

import os
import sys
import traceback
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

def debug_print(message):
    """è°ƒè¯•æ‰“å°å‡½æ•°"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] DEBUG: {message}")

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from audio_to_images import audio_to_images_pipeline
    debug_print("æˆåŠŸå¯¼å…¥ audio_to_images_pipeline")
except Exception as e:
    print(f"è­¦å‘Šï¼šå¯¼å…¥ audio_to_images_pipeline å¤±è´¥: {e}")
    print(traceback.format_exc())
    raise

try:
    from utils.video_creator import VideoCreator
    debug_print("æˆåŠŸå¯¼å…¥ VideoCreator")
except Exception as e:
    print(f"è­¦å‘Šï¼šå¯¼å…¥ VideoCreator å¤±è´¥: {e}")
    print(traceback.format_exc())
    raise

def audio_to_video_pipeline(audio_path, style="è‰ºæœ¯é£æ ¼", max_images=8, 
                          extract_keywords=True, output_filename=None, 
                          duration_per_image=None, add_text_overlay=False, 
                          transition_duration=1.0, target_resolution=None,
                          use_beat_sync=False):
    """
    éŸ³é¢‘åˆ°è§†é¢‘çš„å®Œæ•´å¤„ç†æµç¨‹
    
    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        style: ç”Ÿæˆå›¾ç‰‡çš„é£æ ¼
        max_images: æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡
        extract_keywords: æ˜¯å¦æå–å…³é”®è¯ï¼ˆå¦åˆ™ä½¿ç”¨å®Œæ•´å¥å­ï¼‰
        output_filename: è¾“å‡ºè§†é¢‘æ–‡ä»¶å
        duration_per_image: æ¯å¼ å›¾åƒæ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè®¾ç½®ä¸º"auto"æ—¶è‡ªåŠ¨è®¡ç®—
        add_text_overlay: æ˜¯å¦æ·»åŠ æ–‡å­—å åŠ 
        transition_duration: è½¬åœºåŠ¨ç”»æ—¶é•¿ï¼ˆç§’ï¼‰
        target_resolution: è§†é¢‘ç›®æ ‡åˆ†è¾¨ç‡ï¼Œå¦‚(1920, 1080)
        use_beat_sync: æ˜¯å¦æ ¹æ®éŸ³ä¹èŠ‚å¥åˆ‡æ¢å›¾ç‰‡
    
    è¿”å›:
        ç”Ÿæˆçš„è§†é¢‘è·¯å¾„
    """
    try:
        print(f"\n{'='*60}")
        print(f"å¼€å§‹éŸ³é¢‘åˆ°è§†é¢‘çš„å®Œæ•´å¤„ç†æµç¨‹...")
        print(f"{'='*60}")
        
        # 1. é¦–å…ˆä½¿ç”¨ audio_to_images_pipeline ç”Ÿæˆå›¾ç‰‡
        print("\nğŸ“‹ ç¬¬ä¸€æ­¥ï¼šä»éŸ³é¢‘ç”Ÿæˆå›¾ç‰‡")
        image_paths = audio_to_images_pipeline(
            audio_path=audio_path,
            style=style,
            max_images=max_images,
            extract_keywords=extract_keywords
        )
        
        if not image_paths:
            raise ValueError("æ— æ³•ç”Ÿæˆå›¾ç‰‡ï¼Œè§†é¢‘åˆ›å»ºå¤±è´¥")
        
        print(f"\nğŸ“‹ ç¬¬äºŒæ­¥ï¼šå°†ç”Ÿæˆçš„å›¾ç‰‡è½¬æ¢ä¸ºè§†é¢‘")
        print(f"ä½¿ç”¨ {len(image_paths)} å¼ å›¾ç‰‡åˆ›å»ºè§†é¢‘")
        
        # 2. åˆ›å»ºè§†é¢‘
        video_creator = VideoCreator()
        
        if use_beat_sync:
            print("ğŸµ ä½¿ç”¨éŸ³ä¹èŠ‚å¥åŒæ­¥æ¨¡å¼")
            video_path = video_creator.create_slideshow_with_beat(
                image_paths=image_paths,
                audio_path=audio_path,
                output_filename=output_filename
            )
        else:
            print("â±ï¸ ä½¿ç”¨å›ºå®šæ—¶é•¿æ¨¡å¼")
            video_path = video_creator.create_slideshow(
                image_paths=image_paths,
                audio_path=audio_path,
                output_filename=output_filename,
                duration_per_image=duration_per_image,
                transition_duration=transition_duration,
                target_resolution=target_resolution
            )
        
        if not video_path:
            raise ValueError("è§†é¢‘åˆ›å»ºå¤±è´¥")
        
        print(f"\nâœ… è§†é¢‘åˆ›å»ºæˆåŠŸ: {video_path}")
        
        # 3. å¯é€‰ï¼šæ·»åŠ æ–‡å­—å åŠ 
        if add_text_overlay:
            print("\nğŸ“ ç¬¬ä¸‰æ­¥ï¼šæ·»åŠ æ–‡å­—å åŠ åˆ°è§†é¢‘")
            
            # å°è¯•ä»è½¬å½•æ–‡ä»¶ä¸­è·å–æ–‡å­—å†…å®¹
            try:
                # è·å–æœ€è¿‘çš„è½¬å½•æ–‡ä»¶
                transcript_dir = Path("output/transcribed")
                if transcript_dir.exists():
                    # æŸ¥æ‰¾ä¸å½“å‰éŸ³é¢‘ç›¸å…³çš„æœ€æ–°è½¬å½•æ–‡ä»¶
                    audio_name = os.path.splitext(os.path.basename(audio_path))[0]
                    transcript_files = list(transcript_dir.glob(f"{audio_name}_*_transcript.txt"))
                    
                    if transcript_files:
                        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
                        transcript_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
                        latest_transcript = transcript_files[0]
                        
                        print(f"ğŸ” æ‰¾åˆ°æœ€è¿‘çš„è½¬å½•æ–‡ä»¶: {latest_transcript}")
                        
                        # è¯»å–è½¬å½•å†…å®¹
                        with open(latest_transcript, "r", encoding="utf-8") as f:
                            transcript = f.read()
                        
                        # ç®€å•åˆ†å‰²æ–‡æœ¬ï¼Œä¸ºæ¯ä¸ªå›¾ç‰‡åˆ›å»ºä¸€ä¸ªæ–‡å­—ç‰‡æ®µ
                        # è¿™é‡Œä½¿ç”¨ç®€å•çš„ç­–ç•¥ï¼Œå®é™…åº”ç”¨å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ–‡æœ¬åˆ†å‰²
                        words = transcript.split()
                        segment_length = max(1, len(words) // len(image_paths))
                        
                        # ç”Ÿæˆæ–‡å­—åˆ—è¡¨
                        text_list = []
                        current_time = 0
                        
                        # å°è¯•ç¡®å®šæ¯å¼ å›¾ç‰‡çš„æ˜¾ç¤ºæ—¶é•¿
                        if duration_per_image and duration_per_image != "auto":
                            img_duration = duration_per_image
                        else:
                            # ä¼°ç®—æ—¶é•¿
                            from utils.audio_processor import AudioProcessor
                            processor = AudioProcessor("tiny")  # ä½¿ç”¨tinyæ¨¡å‹å¿«é€Ÿè·å–éŸ³é¢‘æ—¶é•¿
                            audio_duration = processor.get_audio_duration(audio_path)
                            img_duration = audio_duration / len(image_paths)
                        
                        for i in range(len(image_paths)):
                            start_idx = i * segment_length
                            end_idx = min((i + 1) * segment_length, len(words))
                            text = " ".join(words[start_idx:end_idx])
                            
                            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
                            if not text and i < len(words):
                                text = words[i] if i < len(words) else f"å›¾ç‰‡ {i+1}"
                            elif not text:
                                text = f"å›¾ç‰‡ {i+1}"
                            
                            text_list.append({
                                'text': text,
                                'start_time': current_time,
                                'duration': img_duration
                            })
                            current_time += img_duration
                        
                        print(f"ğŸ“ å‡†å¤‡æ·»åŠ  {len(text_list)} æ®µæ–‡å­—åˆ°è§†é¢‘")
                        
                        # æ·»åŠ æ–‡å­—å åŠ 
                        video_with_text = video_creator.add_text_overlay(
                            video_path=video_path,
                            text_list=text_list
                        )
                        
                        if video_with_text and video_with_text != video_path:
                            print(f"âœ… æ–‡å­—å åŠ å®Œæˆ: {video_with_text}")
                            video_path = video_with_text
                        else:
                            print("âš ï¸ æ–‡å­—å åŠ å¤±è´¥æˆ–æœªæ·»åŠ æ–°æ–‡å­—")
                    else:
                        print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³çš„è½¬å½•æ–‡ä»¶ï¼Œè·³è¿‡æ–‡å­—å åŠ ")
                else:
                    print("âš ï¸ è½¬å½•æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ–‡å­—å åŠ ")
            except Exception as e:
                print(f"âŒ æ·»åŠ æ–‡å­—å åŠ æ—¶å‡ºé”™: {e}")
                print("å°†ç»§ç»­ä½¿ç”¨æ²¡æœ‰æ–‡å­—å åŠ çš„è§†é¢‘")
        
        print(f"\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print(f"æœ€ç»ˆç”Ÿæˆçš„è§†é¢‘: {video_path}")
        print(f"\næ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è§†é¢‘:")
        print(f"  explorer.exe {os.path.dirname(video_path)}")
        
        return video_path
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†æµç¨‹å‡ºé”™: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        return None

def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°"""
    import argparse
    
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    print("æ£€æŸ¥å¿…è¦çš„ç›®å½•...")
    for dir_path in ["output/images", "output/transcribed", "output/videos"]:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    print("ç›®å½•æ£€æŸ¥å®Œæˆ")
    
    parser = argparse.ArgumentParser(description='éŸ³é¢‘è½¬è§†é¢‘çš„å®Œæ•´å¤„ç†å·¥å…·')
    parser.add_argument('--audio', required=True, help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--style', default='è‰ºæœ¯é£æ ¼', help='ç”Ÿæˆå›¾ç‰‡çš„é£æ ¼')
    parser.add_argument('--max-images', type=int, default=8, help='æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡')
    parser.add_argument('--full-sentences', action='store_true', help='ä½¿ç”¨å®Œæ•´å¥å­è€Œä¸æ˜¯æå–å…³é”®è¯')
    parser.add_argument('--output-filename', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶å')
    parser.add_argument('--duration', type=float, help='æ¯å¼ å›¾åƒæ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰')
    parser.add_argument('--add-text', action='store_true', help='æ·»åŠ æ–‡å­—å åŠ ')
    parser.add_argument('--transition', type=float, default=1.0, help='è½¬åœºåŠ¨ç”»æ—¶é•¿ï¼ˆç§’ï¼‰')
    parser.add_argument('--resolution', help='ç›®æ ‡åˆ†è¾¨ç‡ï¼Œæ ¼å¼å¦‚ 1920x1080')
    parser.add_argument('--beat-sync', action='store_true', help='æ ¹æ®éŸ³ä¹èŠ‚å¥åˆ‡æ¢å›¾ç‰‡')
    
    args = parser.parse_args()
    
    # è§£æåˆ†è¾¨ç‡å‚æ•°
    target_resolution = None
    if args.resolution:
        try:
            width, height = map(int, args.resolution.split('x'))
            target_resolution = (width, height)
            print(f"è®¾ç½®è§†é¢‘åˆ†è¾¨ç‡: {width}x{height}")
        except ValueError:
            print(f"è­¦å‘Šï¼šæ— æ•ˆçš„åˆ†è¾¨ç‡æ ¼å¼ {args.resolution}ï¼Œå°†ä½¿ç”¨é»˜è®¤è®¾ç½®")
    
    print(f"\nå¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: {args.audio}")
    print(f"å›¾ç‰‡é£æ ¼: {args.style}")
    print(f"æœ€å¤§å›¾ç‰‡æ•°é‡: {args.max_images}")
    print(f"ä½¿ç”¨{'å®Œæ•´å¥å­' if args.full_sentences else 'å…³é”®è¯'}ç”Ÿæˆå›¾ç‰‡")
    
    if args.beat_sync:
        print("å¯ç”¨éŸ³ä¹èŠ‚å¥åŒæ­¥æ¨¡å¼")
    elif args.duration:
        print(f"æ¯å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿: {args.duration}ç§’")
    
    if args.add_text:
        print("å°†æ·»åŠ æ–‡å­—å åŠ ")
    
    video_path = audio_to_video_pipeline(
        audio_path=args.audio,
        style=args.style,
        max_images=args.max_images,
        extract_keywords=not args.full_sentences,
        output_filename=args.output_filename,
        duration_per_image=args.duration,
        add_text_overlay=args.add_text,
        transition_duration=args.transition,
        target_resolution=target_resolution,
        use_beat_sync=args.beat_sync
    )
    
    if video_path:
        print(f"\nâœ… æ‰€æœ‰å¤„ç†å·²å®Œæˆï¼")
    else:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        sys.exit(1)

if __name__ == "__main__":
    main()